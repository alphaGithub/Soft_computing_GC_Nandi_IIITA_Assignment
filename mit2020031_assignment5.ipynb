{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5:\n",
    "<h2>Question :</h2>\n",
    "Design a Naïve Bayes classifier for filtering Spam and Ham (Normal) messages from your mail box.. Make a comparative study on the performance of all the three models of Naïve Bayes classifiers. The SMS data set, together with a readme file from UCI Machine Learning Repository, has been provided for your ready reference in the appropriate link on my website.\n",
    "<br>\n",
    "Hints: \n",
    "1. you may go through this 11 min video: <br>\n",
    "https://www.youtube.com/watch?v=99MN-rl8jGY <br>\n",
    "2. However, You are allowed to use only Python NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading required package\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data set from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data set\n",
    "read_data = np.loadtxt(\"spam ham data set.csv\",encoding=\"latin-1\" ,dtype=np.str,delimiter=\"\\t\")\n",
    "read_data = read_data[2:]        #removing top 2 useless rows of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning dataset\n",
    "<ul>\n",
    "    <li>1.convert sms massages to lower case.</li>\n",
    "    <li>2.remove all punchuations.</li>\n",
    "    <li>3.split msg to list and remove words with length smaller than 3 from list</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning text\n",
    "import string        #package to get puchuation list(no other use has been done of this package)\n",
    "exclist = string.punctuation + string.digits           # contain puchuation !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~0123456789\n",
    "y_msg=[]\n",
    "x_msg=[]\n",
    "\n",
    "for msg in read_data:\n",
    "    msg = msg.lower()\n",
    "    if msg[0]=='h':                #sepearating ham and spam, setting ham=0 and spam=1\n",
    "        msg = msg[4:]\n",
    "        y_msg.append(0)\n",
    "    elif msg[0]=='s':\n",
    "        msg = msg[3:]\n",
    "        y_msg.append(1)\n",
    "\n",
    "    for s in exclist:            #removing punchuation\n",
    "         msg = msg.replace(s, '')\n",
    "    msg = msg.replace('\\W+', '').replace('\\s+', ' ').strip()\n",
    "    msg = msg.split()            #splitting msg\n",
    "\n",
    "    to_remove = []\n",
    "    for m in msg:                 #removing words of length less than 2( a , if ,ok ,is ,etc)\n",
    "        if len(m)<=2:\n",
    "            to_remove.append(m)\n",
    "    for r in to_remove:\n",
    "        msg.remove(r)\n",
    "        \n",
    "    x_msg.append(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vacobulary from input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Vacobulary -> 8381\n",
      "\n",
      "Top 20 elements in vacobulary -> ['aah', 'aaooooright', 'aathilove', 'aathiwhere', 'abbey', 'abdomen', 'abeg', 'abelu', 'aberdeen', 'abi', 'ability', 'abiola', 'abj', 'able', 'abnormally', 'about', 'aboutas', 'above', 'abroad', 'absence']\n"
     ]
    }
   ],
   "source": [
    "#creating vacobulary\n",
    "vacob = []\n",
    "for msg in x_msg:\n",
    "    for word in msg:\n",
    "        if word not in vacob:\n",
    "            vacob.append(word)\n",
    "vacob.sort()\n",
    "print(\"Length of Vacobulary ->\",len(vacob))\n",
    "print(\"\\nTop 20 elements in vacobulary ->\",vacob[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vector from vacobulary:\n",
    "for example : vacobulary = [\"Hello\", \"Dear\",\"How\" ,\"Money\",\"zone\"] \\\n",
    "              $x_j$ = [\"Hello\",\"Dear\",\"Hello\"] \\\n",
    "              vector($x_j$) = [2,1,0,0,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data ->  5573 , 8381\n"
     ]
    }
   ],
   "source": [
    "#converting data to frequecy table which will be used as dataset\n",
    "m = len(y)\n",
    "n = len(vacob)\n",
    "print(\"Shape of data -> \",m,\",\",n)\n",
    "\n",
    "x_data_list = []\n",
    "for i in range(m):\n",
    "    x_j = []\n",
    "    for v in vacob:\n",
    "        freq = x_msg[i].count(v)\n",
    "        x_j.append(freq)\n",
    "    x_data_list.append(x_j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all data to numpy for further use\n",
    "x_data = np.array(x_data_list)\n",
    "y_data = np.array(y_msg).reshape((m,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data set, 75 % training and 25% as testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset -> (4179, 8381) (4179, 1)\n",
      "Testing dataset  -> (1394, 8381) (1394, 1)\n"
     ]
    }
   ],
   "source": [
    "#splitting of data into training and testing dataset\n",
    "m,n=x_data.shape\n",
    "k = int(m*0.75)\n",
    "x_train = x_data[:k]\n",
    "y_train = y_data[:k]\n",
    "x_test = x_data[k:]\n",
    "y_test = y_data[k:]\n",
    "print(\"Training dataset ->\",x_train.shape,y_train.shape)\n",
    "print(\"Testing dataset  ->\",x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Naive Bayes Classifier for filtering spam and ham messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Multivariate Bernoulli Event Model :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\phi_{y^{(i)}=1} = \\frac{ \\sum_{i=1}^{m} 1\\{ y^{(i)} =1\\}}{m} \\\\\n",
    "    \\phi_{y^{(i)}=0} = 1-\\phi_{y^{(i)}=1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_1 -> 0.13519980856664274\n",
      "phi_0 -> 0.8648001914333573\n"
     ]
    }
   ],
   "source": [
    "m,n = x_train.shape\n",
    "phi_1 = np.sum(y_train)/m\n",
    "phi_0 = 1-phi_1\n",
    "print(\"phi_1 ->\",phi_1)\n",
    "print(\"phi_0 ->\",phi_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\phi_{j/y=0} = \\frac{\\sum_{i=1}^{m} 1\\{ x_j^{(i)}=1 \\wedge y^{(i)} =0\\} }{ \\sum_{i=1}^{m} 1\\{ y^{(i)} =0\\} }\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\phi_{j/y=1} = \\frac{\\sum_{i=1}^{m} 1\\{ x_j^{(i)}=1 \\wedge y^{(i)} =1\\} }{ \\sum_{i=1}^{m} 1\\{ y^{(i)} =1\\} }\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_j_y0 = []\n",
    "phi_j_y1 = []\n",
    "sum_y1 = np.sum(y_train)\n",
    "sum_y0 = m-sum_y1\n",
    "\n",
    "for j in range(n):\n",
    "    count_y0=0\n",
    "    count_y1=0\n",
    "    for i in range(m):\n",
    "        if y_train[i]==0 and x_train[i][j]>=1:\n",
    "            count_y0 += 1\n",
    "        elif y_train[i]==1 and x_train[i][j]>=1:\n",
    "            count_y1 += 1\n",
    "    phi_j_y0.append(count_y0/sum_y0)\n",
    "    phi_j_y1.append(count_y1/sum_y1)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function to predict and compute Accuracy :\n",
    "\\begin{equation}\n",
    "P(y_{=1}/x_j) = \\frac{P(x_j/y)P(y)}{P(x_j)} \\\\\n",
    "prediction = argmax_y(P(y/x))\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict result\n",
    "def predict(x):\n",
    "    p_0=phi_0\n",
    "    p_1=phi_1\n",
    "    for j in range(x.shape[0]):\n",
    "        if x[j]==1:\n",
    "            px_y0 = phi_j_y0[j]\n",
    "            px_y1 = phi_j_y1[j]\n",
    "            if px_y0==0:\n",
    "                px_y0=0.000000000001 #cases where px_y= 0\n",
    "            if px_y1==0:\n",
    "                px_y1=0.000000000001\n",
    "                \n",
    "            p_0 = p_0*px_y0\n",
    "            p_1 = p_1*px_y1\n",
    "    \n",
    "    if p_0 < p_1:   #argmax\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "            \n",
    "    print(p_0,p_1)\n",
    "\n",
    "#function to compute accuracy \n",
    "def accuracy(x,y):\n",
    "    count = 0\n",
    "    total = x.shape[0]\n",
    "    for i in range(x.shape[0]):\n",
    "        p = predict(x[i])\n",
    "        if p==y[i]:\n",
    "            count += 1\n",
    "    \n",
    "    return (count*100)/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ----> HAM\n",
      "1 ----> SPAM\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [1]    Precited --> 1\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 1\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n"
     ]
    }
   ],
   "source": [
    "#Preciting some results :\n",
    "# 0 = ham\n",
    "# 1 = spam\n",
    "print(\"0 ----> HAM\")\n",
    "print(\"1 ----> SPAM\")\n",
    "for i in range(10):\n",
    "    print(\"Actual ->\",y_test[i],\"   Precited -->\",predict(x_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of Multivariate bernoulli event model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  97.05882352941177 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \",accuracy(x_test,y_test),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Multinomial Event Model :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $\\phi_{y^{(i)}=0}$ , $\\phi_{y^{(i)}=1}$\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi_{y^{(i)}=0} = \\frac{\\sum_{i=1}^{m} \\{ y^{(i)}=0 \\}}{m} \\\\\n",
    "\\phi_{y^{(i)}=1} = \\frac{\\sum_{i=1}^{m} \\{ y^{(i)}=1 \\}}{m} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_y0 ---->  0.8648001914333573\n",
      "phi_y1 ---->  0.13519980856664274\n"
     ]
    }
   ],
   "source": [
    "phi_y1 = np.sum(y_train)/y_train.shape[0]\n",
    "phi_y0 = 1- phi_y1\n",
    "print(\"phi_y0 ----> \",phi_y0)\n",
    "print(\"phi_y1 ----> \",phi_y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $\\phi_{x/y^{(i)}=0}$ , $\\phi_{x/y^{(i)}=1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.81080473e-05 2.81080473e-05 8.43241420e-05 ... 2.81080473e-05\n",
      " 5.62160947e-05 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "m,n = x_train.shape\n",
    "sum_x0 = np.zeros(n)\n",
    "sum_x1 = np.zeros(n)\n",
    "for i in range(m):\n",
    "    if y[i]==1:\n",
    "        sum_x1 += x_train[i]\n",
    "    else:\n",
    "        sum_x0 += x_train[i]\n",
    "        \n",
    "num_words0 = np.sum(sum_x0)\n",
    "num_words1 = np.sum(sum_x1)\n",
    "\n",
    "phi_x_y0 = sum_x0/num_words0\n",
    "phi_x_y1 = sum_x1/num_words1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function to predict and calculate accuracy.\n",
    "\\begin{equation}\n",
    "    Precition = argmax_y P(y/x) \\\\\n",
    "    P(y/x) = \\frac{P(x/y)P(y)}{P(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multinomial(x):\n",
    "    p_0=phi_y0\n",
    "    p_1=phi_y0\n",
    "    for j in range(x.shape[0]):\n",
    "        if x[j]==1:\n",
    "            px_y0 = phi_x_y0[j]\n",
    "            px_y1 = phi_x_y1[j]\n",
    "            if px_y0==0:\n",
    "                px_y0=0.000000000001 #cases where px_y= 0\n",
    "            if px_y1==0:\n",
    "                px_y1=0.000000000001\n",
    "                \n",
    "            p_0 = p_0*px_y0\n",
    "            p_1 = p_1*px_y1\n",
    "    \n",
    "    if p_0 < p_1:   #argmax\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "            \n",
    "    print(p_0,p_1)\n",
    "\n",
    "#function to compute accuracy \n",
    "def accuracy_multinomial(x,y):\n",
    "    count = 0\n",
    "    total = x.shape[0]\n",
    "    for i in range(x.shape[0]):\n",
    "        p = predict_multinomial(x[i])\n",
    "        if p==y[i]:\n",
    "            count += 1\n",
    "    \n",
    "    return (count*100)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ----> HAM\n",
      "1 ----> SPAM\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [1]    Precited --> 1\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 1\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n",
      "Actual -> [0]    Precited --> 0\n"
     ]
    }
   ],
   "source": [
    "#Preciting some results :\n",
    "# 0 = ham\n",
    "# 1 = spam\n",
    "print(\"0 ----> HAM\")\n",
    "print(\"1 ----> SPAM\")\n",
    "for i in range(10):\n",
    "    print(\"Actual ->\",y_test[i],\"   Precited -->\",predict_multinomial(x_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy using Multinomial envent Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  96.91535150645625 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \",accuracy_multinomial(x_test,y_test),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Guassian Discriminant Analysis Model :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $\\phi$ using the formula :\n",
    "\\begin{equation}\n",
    "    \\phi = \\frac{1}{m} \\sum _{i=1}^{i=m} y^{(i)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 0.13519980856664274\n"
     ]
    }
   ],
   "source": [
    "def calculate_phi(y):\n",
    "    m,n = y.shape\n",
    "    return np.sum(y)/m\n",
    "\n",
    "print(\"->\",calculate_phi(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $\\mu_0$ , $\\mu_1$ using the formula :\n",
    "\\begin{equation}\n",
    "    \\mu_0 = \\frac{\\sum_{i=1}^{i=m}1(y^{(i)}=0)x^{(i)}}{\\sum_{i=1}^{i=m}1(y^{(i)}=0)} \\\\\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\mu_1 = \\frac{\\sum_{i=1}^{i=m}1(y^{(i)}=1)x^{(i)}}{\\sum_{i=1}^{i=m}1(y^{(i)}=1)} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u0,u1 ->\n",
      "[[0.0002767  0.0002767  0.00083011 ... 0.0002767  0.0005534  0.        ]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_mu0(x,y):\n",
    "    m,n = x.shape\n",
    "    num=np.zeros((1,n))\n",
    "    den=0\n",
    "    for i in range(m):\n",
    "        if y[i]==0:\n",
    "            num += x[i]\n",
    "            den += 1\n",
    "    #print(num)\n",
    "    return num/den\n",
    "\n",
    "def calculate_mu1(x,y):\n",
    "    m,n = x.shape\n",
    "    num=np.zeros((1,n))\n",
    "    den=0\n",
    "    for i in range(m):\n",
    "        if y[i]==1:\n",
    "            num += x[i]\n",
    "            den += 1\n",
    "    return num/den\n",
    "\n",
    "print(\"u0,u1 ->\")\n",
    "print(calculate_mu0(x_train,y_train))\n",
    "print(calculate_mu1(x_train,y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate $\\sum$ using the formula:\n",
    "\\begin{equation}\n",
    "    \\sum = \\frac{1}{m} \\sum _{i=1}^{i=m} (x-\\mu_{y_{(i)}}). (x-\\mu_{y_{(i)}})^T\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma :\n"
     ]
    }
   ],
   "source": [
    "def calculate_sigma(x,y,mu_0,mu_1):\n",
    "    m,n = x.shape\n",
    "    sigma = np.zeros((n,n))\n",
    "    for i  in range(m):\n",
    "        x_i = x[i]\n",
    "        y_i = y[i]\n",
    "        if y_i == 1:\n",
    "            k = (x_i-mu_1).T\n",
    "        else:\n",
    "            k = (x_i-mu_0).T\n",
    "        sigma += k*k.T\n",
    "    sigma = sigma/m\n",
    "    return sigma\n",
    "\n",
    "print(\"sigma :\")\n",
    "sigma = calculate_sigma(x_train,y_train,calculate_mu0(x_train,y_train),calculate_mu1(x_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating class prior ,i.e class prior :P(y)\n",
    "\\begin{equation}\n",
    "    P(y^{(i)};\\phi) = \\phi^{y^{(i)}} (1-\\phi)^{1-y^{(i)}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_py(y_i,phi):\n",
    "    if y_i==1:\n",
    "        return phi\n",
    "    else:\n",
    "        return 1-phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi -> 0.13519980856664274\n",
      "mu_0 -> [[0.0002767  0.0002767  0.00083011 ... 0.0002767  0.0005534  0.        ]]\n",
      "mu_1 -> [[0. 0. 0. ... 0. 0. 0.]]\n",
      "sigma ->\n",
      " [[ 2.39225484e-04 -6.62124230e-08 -1.98637269e-07 ... -6.62124230e-08\n",
      "  -1.32424846e-07  0.00000000e+00]\n",
      " [-6.62124230e-08  2.39225484e-04 -1.98637269e-07 ... -6.62124230e-08\n",
      "  -1.32424846e-07  0.00000000e+00]\n",
      " [-1.98637269e-07 -1.98637269e-07  7.17279178e-04 ... -1.98637269e-07\n",
      "  -3.97274538e-07  0.00000000e+00]\n",
      " ...\n",
      " [-6.62124230e-08 -6.62124230e-08 -1.98637269e-07 ...  2.39225484e-04\n",
      "  -1.32424846e-07  0.00000000e+00]\n",
      " [-1.32424846e-07 -1.32424846e-07 -3.97274538e-07 ... -1.32424846e-07\n",
      "   4.78318543e-04  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#using above function to find all required values\n",
    "phi  = calculate_phi(y_train)\n",
    "mu_0 = calculate_mu0(x_train,y_train)\n",
    "mu_1 = calculate_mu1(x_train,y_train)\n",
    "print(\"phi ->\",phi)\n",
    "print(\"mu_0 ->\",mu_0)\n",
    "print(\"mu_1 ->\",mu_1)\n",
    "print(\"sigma ->\\n\",sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Likelihood of a feature to be in a class ,i.e. P(x/y;$\\mu,\\sum$) using formula :\n",
    "\\begin{equation}\n",
    "    P(x/y ; \\mu , \\sum) = \\frac{1}{(2\\pi)^{\\frac{n}{2}}|\\sum|^{\\frac{1}{2}}} exp(-\\frac{1}{2}(x-\\mu)^T \\sum^{-1} (x-\\mu))\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_px_y(x,mu,sigma):\n",
    "    m = x.shape[0]\n",
    "    x = x.reshape(1,m)\n",
    "    n = 2 #number of class\n",
    "    x_u = (x-mu).T\n",
    "    x_u_t = x_u.T\n",
    "    det_sigma = np.linalg.det(sigma)\n",
    "    inv_sigma = np.linalg.inv(sigma)\n",
    "    np.matmul(np.matmul(x_u_t,inv_sigma),x_u)\n",
    "    px_y = np.exp(-0.5*np.matmul(np.matmul(x_u_t,inv_sigma),x_u)) /( np.power((2*np.pi),n/2)* np.sqrt(det_sigma))\n",
    "    return px_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failed\n",
    "$\\sum$ is singular matrix, gives error while compting inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_px_y(x_test[0],mu_1,sigma))\n",
    "print(calculate_px_y(x_test[0],mu_0,sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate P(y/x) for prediction:\n",
    "\\begin{equation}\n",
    "   P(y/x) = \\frac{P(x/y)P(y)}{P(x)} \\\\\n",
    "   P(x) = constant\\ for\\ both\\ class \\\\\n",
    "   Prediction = argmax_y \\frac{P(x/y)P(y)}{P(x)}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gda(x,phi,mu_0,mu_1,sigma):\n",
    "    p0 = calculate_px_y(x,mu_0,sigma)*calculate_py(0,phi)\n",
    "    p1 = calculate_px_y(x,mu_1,sigma)*calculate_py(1,phi)\n",
    "    if p0>p1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def accuracy_gda(x_test,y_test,phi,mu_0,mu_1,sigma):\n",
    "    m,n = x_test.shape\n",
    "    count = 0\n",
    "    for i in range(m):\n",
    "        y_predict = predict_gda(x_test[i],phi,mu_0,mu_1,sigma)\n",
    "        if y_predict==y_test[i]:\n",
    "            count +=1\n",
    "    \n",
    "    return count*100/m\n",
    "\n",
    "print(\"Accuracy = \",accuracy_gda(x_test,y_test,phi,mu_0,mu_1,sigma),end=\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results :\n",
    "<ul>\n",
    "    <li>1. Accuracy of Multivariate Bernoulli = 97.058 %</li>\n",
    "    <li>2. Accuracy of Multinomial event Model =  96.91535 %</li>\n",
    "    <li>3. GDA failed to predit,because $\\sum^{-1}$ cannot be computed as $\\sum$ is singular matrix</li>\n",
    "    </ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis :\n",
    "<ul>\n",
    "    <li>Simpler and faster if dataset in available in proper format.</li>\n",
    "    <li>Preprocessing data and cleaning, creating matrix is more complex than desiging predictor.</li>\n",
    "    <li>Multivariate Bernoulli has better Accuracy compared to Multinomial event model with very less difference.</li>\n",
    "    <li>GDA is less efficent in terms of time, compting parameter took longer time.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
